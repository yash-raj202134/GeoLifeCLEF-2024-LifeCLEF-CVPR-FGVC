{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick start XGBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Dataset/geolifeclef-2024/\"\n",
    "\n",
    "train = pd.read_csv(path +\"GLC24_PA_metadata_train.csv\")\n",
    "test = pd.read_csv(path+\"GLC24_PA_metadata_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_train = pd.read_csv(path+\"EnvironmentalRasters/EnvironmentalRasters/Elevation/GLC24-PA-train-elevation.csv\")\n",
    "elevation_test = pd.read_csv(path+\"EnvironmentalRasters/EnvironmentalRasters/Elevation/GLC24-PA-test-elevation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_footprint_train = pd.read_csv(path+\"EnvironmentalRasters/EnvironmentalRasters/Human Footprint/GLC24-PA-train-human_footprint.csv\")\n",
    "human_footprint_test = pd.read_csv(path+\"EnvironmentalRasters/EnvironmentalRasters/Human Footprint/GLC24-PA-test-human_footprint.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover_test = pd.read_csv(path+\"EnvironmentalRasters/EnvironmentalRasters/LandCover/GLC24-PA-test-landcover.csv\")\n",
    "landcover_train = pd.read_csv(path+\"EnvironmentalRasters/EnvironmentalRasters/LandCover/GLC24-PA-train-landcover.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "soilgrids_test = pd.read_csv(path+\"EnvironmentalRasters/EnvironmentalRasters/SoilGrids/GLC24-PA-test-soilgrids.csv\")\n",
    "soilgrids_train = pd.read_csv(path+\"EnvironmentalRasters/EnvironmentalRasters/SoilGrids/GLC24-PA-train-soilgrids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1483637, 9)\n",
      "(1483637, 10)\n",
      "(1483637, 26)\n",
      "(1483637, 27)\n",
      "(1483637, 36)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "for dataset in [elevation_train, human_footprint_train, landcover_train, soilgrids_train]:\n",
    "    train = pd.merge(train, dataset, how = \"left\", left_on = \"surveyId\", right_on = \"surveyId\")\n",
    "    print(train.shape)\n",
    "    del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4716, 8)\n",
      "(4716, 9)\n",
      "(4716, 25)\n",
      "(4716, 26)\n",
      "(4716, 35)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "for dataset in [elevation_test, human_footprint_test, landcover_test, soilgrids_test]:\n",
    "    test = pd.merge(test, dataset, how = \"left\", left_on = \"surveyId\", right_on = \"surveyId\")\n",
    "    print(test.shape)\n",
    "    del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter regions and rarest species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1483637, 36)\n",
      "(1465435, 36)\n"
     ]
    }
   ],
   "source": [
    "#If the region is not in test, we drop it\n",
    "print(train.shape)\n",
    "train = train[train[\"region\"].isin(test[\"region\"].unique())]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1465435, 36)\n",
      "(1432730, 36)\n"
     ]
    }
   ],
   "source": [
    "NB_SPECIES_TO_KEEP = 1000 # Choose the number of most present species you want to keep in each region\n",
    "\n",
    "print(train.shape)\n",
    "species_to_keep = {}\n",
    "\n",
    "for region in train[\"region\"].unique():\n",
    "    species_to_keep[region] = list(train[train[\"region\"] == region][\"speciesId\"].value_counts().index[:NB_SPECIES_TO_KEEP])\n",
    "    \n",
    "train = train[train.apply(lambda row: row['speciesId'] in species_to_keep[row['region']], axis=1)]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regroup all species by survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88571, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surveyId</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>year</th>\n",
       "      <th>geoUncertaintyInM</th>\n",
       "      <th>areaInM2</th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>HumanFootprint-Built1994</th>\n",
       "      <th>...</th>\n",
       "      <th>Soilgrid-bdod</th>\n",
       "      <th>Soilgrid-cec</th>\n",
       "      <th>Soilgrid-cfvo</th>\n",
       "      <th>Soilgrid-clay</th>\n",
       "      <th>Soilgrid-nitrogen</th>\n",
       "      <th>Soilgrid-phh2o</th>\n",
       "      <th>Soilgrid-sand</th>\n",
       "      <th>Soilgrid-silt</th>\n",
       "      <th>Soilgrid-soc</th>\n",
       "      <th>speciesId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212</td>\n",
       "      <td>3.099038</td>\n",
       "      <td>43.134956</td>\n",
       "      <td>2021</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>MEDITERRANEAN</td>\n",
       "      <td>France</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>[1304, 9030, 8784, 4530, 9458, 51, 11157, 982,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222</td>\n",
       "      <td>9.884560</td>\n",
       "      <td>56.912140</td>\n",
       "      <td>2017</td>\n",
       "      <td>10.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>CONTINENTAL</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>[433, 4499, 9816, 540, 254]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   surveyId       lon        lat  year  geoUncertaintyInM  areaInM2  \\\n",
       "0       212  3.099038  43.134956  2021                5.0     100.0   \n",
       "1       222  9.884560  56.912140  2017               10.0      79.0   \n",
       "\n",
       "          region  country  Elevation  HumanFootprint-Built1994  ...  \\\n",
       "0  MEDITERRANEAN   France       47.0                       0.0  ...   \n",
       "1    CONTINENTAL  Denmark        6.0                       0.0  ...   \n",
       "\n",
       "   Soilgrid-bdod  Soilgrid-cec  Soilgrid-cfvo  Soilgrid-clay  \\\n",
       "0          140.0         214.0          151.0          292.0   \n",
       "1          120.0         225.0          101.0           94.0   \n",
       "\n",
       "   Soilgrid-nitrogen  Soilgrid-phh2o  Soilgrid-sand  Soilgrid-silt  \\\n",
       "0              159.0            73.0          284.0          422.0   \n",
       "1              379.0            58.0          650.0          255.0   \n",
       "\n",
       "   Soilgrid-soc                                          speciesId  \n",
       "0         176.0  [1304, 9030, 8784, 4530, 9458, 51, 11157, 982,...  \n",
       "1         609.0                        [433, 4499, 9816, 540, 254]  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_groupby = {k:[\"first\"] for k in train.columns.drop([\"speciesId\", \"surveyId\"])} \n",
    "dict_groupby[\"speciesId\"] = [list]\n",
    "\n",
    "train[\"speciesId\"] = train[\"speciesId\"].astype(int)\n",
    "train = train.groupby(\"surveyId\").agg(dict_groupby).reset_index()\n",
    "train.columns = [x[0] for x in train.columns]\n",
    "print(train.shape)\n",
    "\n",
    "train[\"speciesId\"] = train[\"speciesId\"].apply(lambda x : list(set(x)))\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess NaN, inf, data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.use_inf_as_na', True)\n",
    "\n",
    "def preprocess(df_to_preprocess:pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df = df_to_preprocess.copy()\n",
    "    df['geoUncertaintyInM']  = df['geoUncertaintyInM'].fillna(df['geoUncertaintyInM'].mode()[0])\n",
    "    df['areaInM2'] = df['areaInM2'].fillna(df['areaInM2'].mean())\n",
    "    df['Elevation'] = df['Elevation'].fillna(df['Elevation'].mode()[0])\n",
    "\n",
    "    for column in df.filter(regex='HumanFootprint').columns:\n",
    "        df[column] = df[column].fillna(df[column].mean())\n",
    "\n",
    "    for column in df.filter(regex='Soilgrid').columns:\n",
    "        df[column] = df[column].fillna(df[column].mode()[0])\n",
    "\n",
    "    columns_to_convert =['Elevation','geoUncertaintyInM','HumanFootprint-Pasture1993', 'HumanFootprint-Pasture2009']\n",
    "\n",
    "    df[columns_to_convert] = df[columns_to_convert].astype(int)\n",
    "\n",
    "    for name,values in df.filter(regex='Soilgrid').items():\n",
    "        df[name] = df[name].astype(int)\n",
    "    \n",
    "    df[\"surveyId\"]=df[\"surveyId\"].astype(int).astype(str)\n",
    "    \n",
    "    df.drop(\"country\", axis = 1, inplace = True)\n",
    "    \n",
    "    df.fillna(0, inplace = True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "train = preprocess(train)\n",
    "test = preprocess(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models training and predict on test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training one model for each region, and predicting top K number of species, K being the mean number of species observed in each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for region MEDITERRANEAN\n",
      "Train set size : (7282, 34)\n",
      "Number of species to predict : 15\n",
      "CPU times: total: 11min 24s\n",
      "Wall time: 19min 24s\n",
      "Training model for region CONTINENTAL\n",
      "Train set size : (43128, 34)\n",
      "Number of species to predict : 17\n",
      "CPU times: total: 29min 20s\n",
      "Wall time: 49min 42s\n",
      "Training model for region ATLANTIC\n",
      "Train set size : (36335, 34)\n",
      "Number of species to predict : 13\n",
      "CPU times: total: 18min 22s\n",
      "Wall time: 34min 12s\n",
      "Training model for region ALPINE\n",
      "Train set size : (1826, 34)\n",
      "Number of species to predict : 26\n",
      "CPU times: total: 7min 55s\n",
      "Wall time: 13min 49s\n",
      "CPU times: total: 1h 7min 53s\n",
      "Wall time: 1h 58min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "# Train one model per region\n",
    "for region in train[\"region\"].unique():\n",
    "    \n",
    "    print(f\"Training model for region {region}\")\n",
    "\n",
    "    # Select train and test data corresponding to the current region\n",
    "    X_train = train[train[\"region\"] == region].copy().set_index(\"surveyId\")\n",
    "    nb_mean_species = int(np.round(X_train[\"speciesId\"].apply(lambda x : len(x)).mean(),0))\n",
    "    print(\"Train set size :\",X_train.shape)\n",
    "    print(\"Number of species to predict :\",nb_mean_species)\n",
    "\n",
    "    X_test = test[test[\"region\"] == region].copy().set_index(\"surveyId\")\n",
    "    X_test.drop(\"region\", axis =1, inplace = True)\n",
    "    \n",
    "    #Label encoding\n",
    "    mlb = MultiLabelBinarizer()\n",
    "\n",
    "    y_train = pd.DataFrame(mlb.fit_transform(X_train[\"speciesId\"]),\n",
    "                       columns=mlb.classes_,\n",
    "                       index=X_train.index)\n",
    "\n",
    "    X_train.drop([\"speciesId\", \"region\"], axis = 1, inplace = True)\n",
    "    X_test = X_test[X_train.columns]\n",
    "    \n",
    "    #Hyperparameters could be optimized depending on the region\n",
    "    xgb_params = {\n",
    "        'objective' : 'binary:logistic',\n",
    "        'eval_metric' : 'logloss',\n",
    "        'colsample_bytree': 0.8,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 9,\n",
    "        'n_estimators': 1000,\n",
    "        'reg_alpha': 0.2,\n",
    "        'reg_lambda': 0.8,\n",
    "        'tree_method':'hist',\n",
    "        'device' : 'gpu:0' #comment this line if not using GPU, or select good GPU\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**xgb_params)\n",
    "\n",
    "    %time model.fit(X_train, y_train)  \n",
    "    \n",
    "    # Predict probabilities to select top-k species\n",
    "    proba_predictions = model.predict_proba(X_test)\n",
    "    classes = mlb.classes_\n",
    "\n",
    "    top_k_species = pd.DataFrame(data=proba_predictions,\n",
    "                                  index=X_test.index,\n",
    "                                  columns=classes).apply(lambda x: pd.Series(x.nlargest(nb_mean_species).index), axis=1)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to output dataframe\n",
    "output = pd.concat([output, top_k_species])\n",
    "\n",
    "\n",
    "# Free memory\n",
    "del model\n",
    "del X_train, X_test, y_train, top_k_species, proba_predictions\n",
    "\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"output/xgb_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
