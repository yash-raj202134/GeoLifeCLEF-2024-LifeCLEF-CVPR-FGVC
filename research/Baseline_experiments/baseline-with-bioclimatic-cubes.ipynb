{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Simple baseline with Bioclimatic Cubes — ResNet18 + Binary Cross Entropy [0.25784]\n","\n","To demonstrate the potential of other data such as Bioclimatic cubes, we offer a straightforward baseline that is baseline on a modified ResNet18 and Binary Cross Entropy but still ranks highly on the leaderboard. The model itself should learn the relationship between the precise climatic history of a given location and its species composition.\n","\n","Considering the significant extent for enhancing performance of this baseline, we encourage you to experiment with various techniques, architectures, losses, etc.\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:07.298310Z","start_time":"2024-04-30T21:25:05.354584Z"},"execution":{"iopub.execute_input":"2024-05-01T13:57:56.173812Z","iopub.status.busy":"2024-05-01T13:57:56.173173Z","iopub.status.idle":"2024-05-01T13:58:02.753705Z","shell.execute_reply":"2024-05-01T13:58:02.752732Z","shell.execute_reply.started":"2024-05-01T13:57:56.173774Z"},"tags":[],"trusted":true},"outputs":[],"source":["import os\n","import torch\n","import tqdm\n","import numpy as np\n","import pandas as pd\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from sklearn.metrics import precision_recall_fscore_support\n","os.chdir(\"../../\")"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-05-01T13:30:07.054038Z","iopub.status.busy":"2024-05-01T13:30:07.053659Z","iopub.status.idle":"2024-05-01T13:30:07.058148Z","shell.execute_reply":"2024-05-01T13:30:07.057269Z","shell.execute_reply.started":"2024-05-01T13:30:07.054008Z"}},"source":["## Data description\n","\n","The Bioclimatic Cubes are created from **four** monthly GeoTIFF CHELSA (https://chelsa-climate.org/timeseries/) time series climatic rasters with a resolution of 30 arc seconds, i.e. approximately 1km. The four variables are the precipitation (pr), maximum- (taxmax), minimum- (tasmin), and mean (tax) daily temperatures per month from January 2000 to June 2019. We provide the data in three forms: (i) raw rasters (GeoTiff images), (ii) CSV file with pre-extracted values for each location, i.e., surveyId, and (iii) data cubes as tensor object (.pt).\n","\n","In this notebook, we will work with just the cubes. The cubes are structured as follows.\n","**Shape**: `(n_year, n_month, n_bio)` where:\n","- `n_year` = 19 (ranging from 2000 to 2018)\n","- `n_month` = 12 (ranging from January 01 to December 12)\n","- `n_bio` = 4 comprising [`pr` (precipitation), `tas` (mean daily air temperature), `tasmin`, `tasmax`]\n","\n","The datacubes can simply be loaded as tensors using PyTorch with the following command :\n","\n","```python\n","import torch\n","torch.load('path_to_file.pt')\n","```\n","\n","**References:**\n","- *Karger, D.N., Conrad, O., Böhner, J., Kawohl, T., Kreft, H., Soria-Auza, R.W., Zimmermann, N.E., Linder, P., Kessler, M. (2017): Climatologies at high resolution for the Earth land surface areas. Scientific Data. 4 170122. https://doi.org/10.1038/sdata.2017.122*\n","\n","- *Karger D.N., Conrad, O., Böhner, J., Kawohl, T., Kreft, H., Soria-Auza, R.W., Zimmermann, N.E, Linder, H.P., Kessler, M. Data from: Climatologies at high resolution for the earth’s land surface areas. Dryad Digital Repository. http://dx.doi.org/doi:10.5061/dryad.kd1d4*"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare custom dataset loader\n","\n","We have to sloightly update the Dataset to provide the relevant data in the appropriate format."]},{"cell_type":"code","execution_count":2,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:32.627928Z","start_time":"2024-04-30T21:25:32.612131Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-01T13:58:02.755818Z","iopub.status.busy":"2024-05-01T13:58:02.755339Z","iopub.status.idle":"2024-05-01T13:58:02.770441Z","shell.execute_reply":"2024-05-01T13:58:02.769453Z","shell.execute_reply.started":"2024-05-01T13:58:02.755789Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[],"source":["class TrainDataset(Dataset):\n","    def __init__(self, data_dir, metadata, subset, transform=None):\n","        self.subset = subset\n","        self.transform = transform\n","        self.data_dir = data_dir\n","        self.metadata = metadata\n","        self.metadata = self.metadata.dropna(subset=\"speciesId\").reset_index(drop=True)\n","        self.metadata['speciesId'] = self.metadata['speciesId'].astype(int)\n","        self.label_dict = self.metadata.groupby('surveyId')['speciesId'].apply(list).to_dict()\n","        \n","        self.metadata = self.metadata.drop_duplicates(subset=\"surveyId\").reset_index(drop=True)\n","\n","    def __len__(self):\n","        return len(self.metadata)\n","\n","    def __getitem__(self, idx):\n","        \n","        survey_id = self.metadata.surveyId[idx]\n","        sample = torch.load(os.path.join(self.data_dir, f\"GLC24-PA-{self.subset}-bioclimatic_monthly_{survey_id}_cube.pt\"))\n","        species_ids = self.label_dict.get(survey_id, [])  # Get list of species IDs for the survey ID\n","        \n","        num_classes = 11255\n","        label = torch.zeros(num_classes)  \n","        for species_id in species_ids:\n","            label_id = species_id\n","            label[label_id] = 1  # Set the corresponding class index to 1 for each species\n","\n","        # Ensure the sample is in the correct format for the transform\n","        if isinstance(sample, torch.Tensor):\n","            sample = sample.permute(1, 2, 0)  # Change tensor shape from (C, H, W) to (H, W, C)\n","            sample = sample.numpy()  \n","\n","        if self.transform:\n","            sample = self.transform(sample)\n","\n","        return sample, label, survey_id\n","    \n","class TestDataset(TrainDataset):\n","    def __init__(self, data_dir, metadata, subset, transform=None):\n","        self.subset = subset\n","        self.transform = transform\n","        self.data_dir = data_dir\n","        self.metadata = metadata\n","        \n","    def __getitem__(self, idx):\n","        \n","        survey_id = self.metadata.surveyId[idx]\n","        sample = torch.load(os.path.join(self.data_dir, f\"GLC24-PA-{self.subset}-bioclimatic_monthly_{survey_id}_cube.pt\"))\n","        \n","        if isinstance(sample, torch.Tensor):\n","            sample = sample.permute(1, 2, 0)  # Change tensor shape from (C, H, W) to (H, W, C)\n","            sample = sample.numpy()\n","\n","        if self.transform:\n","            sample = self.transform(sample)\n","\n","        return sample, survey_id"]},{"cell_type":"markdown","metadata":{},"source":["### Load metadata and prepare data loaders"]},{"cell_type":"code","execution_count":3,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:34.532017Z","start_time":"2024-04-30T21:25:32.615562Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-01T14:01:39.966424Z","iopub.status.busy":"2024-05-01T14:01:39.965699Z","iopub.status.idle":"2024-05-01T14:01:44.698198Z","shell.execute_reply":"2024-05-01T14:01:44.697434Z","shell.execute_reply.started":"2024-05-01T14:01:39.966391Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[],"source":["# Dataset and DataLoader\n","batch_size = 64\n","transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","# Load Training metadata\n","train_data_path = \"Dataset/geolifeclef-2024/TimeSeries-Cubes/TimeSeries-Cubes/GLC24-PA-train-bioclimatic_monthly/\"\n","train_metadata_path = \"Dataset/geolifeclef-2024/GLC24_PA_metadata_train.csv\"\n","train_metadata = pd.read_csv(train_metadata_path)\n","train_dataset = TrainDataset(train_data_path, train_metadata, subset=\"train\", transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","\n","# Load Test metadata\n","test_data_path = \"Dataset/geolifeclef-2024/TimeSeries-Cubes/TimeSeries-Cubes/GLC24-PA-test-bioclimatic_monthly/\"\n","test_metadata_path = \"Dataset/geolifeclef-2024/GLC24_PA_metadata_test.csv\"\n","test_metadata = pd.read_csv(test_metadata_path)\n","test_dataset = TestDataset(test_data_path, test_metadata, subset=\"test\", transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"]},{"cell_type":"markdown","metadata":{},"source":["## Define and initialize the ModifiedResNet18 model\n","\n","To utilize the bioclimatic cubes, which have a shape of [4,19,12] (RASTER-TYPE, YEAR, and MONTH), some minor adjustments must be made to the vanilla ResNet-18. It's important to note that this is just one method for ensuring compatibility with the unusual tensor shape, and experimentation is encouraged."]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:31.014067Z","start_time":"2024-04-30T21:25:31.010060Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-01T14:01:51.748767Z","iopub.status.busy":"2024-05-01T14:01:51.747953Z","iopub.status.idle":"2024-05-01T14:01:51.758895Z","shell.execute_reply":"2024-05-01T14:01:51.757756Z","shell.execute_reply.started":"2024-05-01T14:01:51.748728Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[],"source":["class ModifiedResNet18(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ModifiedResNet18, self).__init__()\n","\n","        self.norm_input = nn.LayerNorm([4,19,12])\n","        self.resnet18 = models.resnet18(weights=None)\n","        # We have to modify the first convolutional layer to accept 4 channels instead of 3\n","        self.resnet18.conv1 = nn.Conv2d(4, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.resnet18.maxpool = nn.Identity()\n","        self.ln = nn.LayerNorm(1000)\n","        self.fc1 = nn.Linear(1000, 2056)\n","        self.fc2 = nn.Linear(2056, num_classes)\n","\n","    def forward(self, x):\n","        x = self.norm_input(x)\n","        x = self.resnet18(x)\n","        x = self.ln(x)\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-01T14:01:53.606916Z","iopub.status.busy":"2024-05-01T14:01:53.606467Z","iopub.status.idle":"2024-05-01T14:01:53.649669Z","shell.execute_reply":"2024-05-01T14:01:53.648765Z","shell.execute_reply.started":"2024-05-01T14:01:53.606881Z"},"tags":[],"trusted":true},"outputs":[],"source":["def set_seed(seed):\n","    # Set seed for Python's built-in random number generator\n","    torch.manual_seed(seed)\n","    # Set seed for numpy\n","    np.random.seed(seed)\n","    # Set seed for CUDA if available\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","        # Set cuDNN's random number generator seed for deterministic behavior\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","set_seed(69)"]},{"cell_type":"code","execution_count":6,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:31.611823Z","start_time":"2024-04-30T21:25:31.607373Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-01T14:01:54.854093Z","iopub.status.busy":"2024-05-01T14:01:54.853403Z","iopub.status.idle":"2024-05-01T14:01:55.448581Z","shell.execute_reply":"2024-05-01T14:01:55.447618Z","shell.execute_reply.started":"2024-05-01T14:01:54.854062Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[],"source":["# Check if cuda is available\n","device = torch.device(\"cpu\")\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"DEVICE = CUDA\")\n","\n","num_classes = 11255 # Number of all unique classes within the PO and PA data.\n","model = ModifiedResNet18(num_classes).to(device)"]},{"cell_type":"markdown","metadata":{},"source":["## Training Loop\n","\n","Nothing special, just a standard Pytorch training loop."]},{"cell_type":"code","execution_count":7,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:32.181927Z","start_time":"2024-04-30T21:25:32.177073Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-01T14:01:56.217269Z","iopub.status.busy":"2024-05-01T14:01:56.216435Z","iopub.status.idle":"2024-05-01T14:01:56.223533Z","shell.execute_reply":"2024-05-01T14:01:56.222610Z","shell.execute_reply.started":"2024-05-01T14:01:56.217238Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\yashr\\anaconda3\\envs\\geoenv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"]}],"source":["# Hyperparameters\n","learning_rate = 0.0002\n","num_epochs = 20\n","positive_weigh_factor = 1.0\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","scheduler = CosineAnnealingLR(optimizer, T_max=25, verbose=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"ExecuteTime":{"start_time":"2024-04-30T21:25:34.536634Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-01T14:01:57.359127Z","iopub.status.busy":"2024-05-01T14:01:57.358266Z","iopub.status.idle":"2024-05-01T14:26:37.671792Z","shell.execute_reply":"2024-05-01T14:26:37.670759Z","shell.execute_reply.started":"2024-05-01T14:01:57.359094Z"},"is_executing":true,"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training for 20 epochs started.\n"]}],"source":["print(f\"Training for {num_epochs} epochs started.\")\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    for batch_idx, (data, targets, _) in enumerate(train_loader):\n","\n","        data = data.to(device)\n","        targets = targets.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(data)\n","\n","        pos_weight = targets*positive_weigh_factor  # All positive weights are equal to 10\n","        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","        loss = criterion(outputs, targets)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 278 == 0:\n","            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}\")\n","\n","    scheduler.step()\n","    print(\"Scheduler:\",scheduler.state_dict())\n","\n","# Save the trained model\n","model.eval()\n","torch.save(model.state_dict(), \"models/resnet18-with-bioclimatic-cubes.pth\")"]},{"cell_type":"markdown","metadata":{},"source":["## Test Loop\n","\n","Again, nothing special, just a standard inference."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2024-05-01T14:29:45.598775Z","iopub.status.busy":"2024-05-01T14:29:45.598365Z","iopub.status.idle":"2024-05-01T14:30:04.101172Z","shell.execute_reply":"2024-05-01T14:30:04.100086Z","shell.execute_reply.started":"2024-05-01T14:29:45.598740Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[],"source":["with torch.no_grad():\n","    all_predictions = []\n","    surveys = []\n","    top_k_indices = None\n","    for data, surveyID in tqdm.tqdm(test_loader, total=len(test_loader)):\n","\n","        data = data.to(device)\n","        \n","        outputs = model(data)\n","        predictions = torch.sigmoid(outputs).cpu().numpy()\n","\n","        # Sellect top-25 values as predictions\n","        top_25 = np.argsort(-predictions, axis=1)[:, :25] \n","        if top_k_indices is None:\n","            top_k_indices = top_25\n","        else:\n","            top_k_indices = np.concatenate((top_k_indices, top_25), axis=0)\n","\n","        surveys.extend(surveyID.cpu().numpy())"]},{"cell_type":"markdown","metadata":{},"source":["## Save prediction file!"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-01T14:50:19.293680Z","iopub.status.busy":"2024-05-01T14:50:19.292729Z","iopub.status.idle":"2024-05-01T14:50:19.399622Z","shell.execute_reply":"2024-05-01T14:50:19.398738Z","shell.execute_reply.started":"2024-05-01T14:50:19.293628Z"},"tags":[],"trusted":true},"outputs":[],"source":["data_concatenated = [' '.join(map(str, row)) for row in top_k_indices]\n","\n","pd.DataFrame(\n","    {'surveyId': surveys,\n","     'predictions': data_concatenated,\n","    }).to_csv(\"research/Baseline_experiments/outputs/baseline-with-bioclimatic-cubes/output.csv\", index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":8171035,"sourceId":64733,"sourceType":"competition"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
